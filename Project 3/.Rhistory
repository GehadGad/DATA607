for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
par(mfrow = c(2, 2))
p_hats1 <- rep(0, 5000)
p_hats2 <- rep(0, 5000)
p_hats3 <- rep(0, 5000)
p_hats4 <- rep(0, 5000)
p <- 0.1
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats1[i] <- sum(samp == "atheist")/n
}
p <- 0.1
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats2[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats3[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
par(mfrow = c(2, 2))
p_hats1 <- rep(0, 5000)
p_hats2 <- rep(0, 5000)
p_hats3 <- rep(0, 5000)
p_hats4 <- rep(0, 5000)
p <- 0.1
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats1[i] <- sum(samp == "atheist")/n
}
p <- 0.1
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats2[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats3[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
par(mfrow = c(2, 2))
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
p_hats1 <- rep(0, 5000)
p_hats2 <- rep(0, 5000)
p_hats3 <- rep(0, 5000)
p_hats4 <- rep(0, 5000)
p <- 0.1
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats1[i] <- sum(samp == "atheist")/n
}
p <- 0.1
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats2[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats3[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
par(mfrow = c(2, 2))
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 400", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.02, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.02, n = 400", xlim = c(0, 0.18))
p_hats1 <- rep(0, 5000)
p_hats2 <- rep(0, 5000)
p_hats3 <- rep(0, 5000)
p_hats4 <- rep(0, 5000)
p <- 0.1
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats1[i] <- sum(samp == "atheist")/n
}
p <- 0.1
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats2[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats3[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
par(mfrow = c(2, 2))
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 400", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.02, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.02, n = 400", xlim = c(0, 0.18))
par(mfrow = c(1, 1))
setwd("~/CUNY/DATA607/Assignments/XML and JSON")
library(XML)
html <- htmlParse(file = "books.html") %>%
read_html(html)
xml <- xmlParse(file = "books.xml") %>%
xmlRoot(xml) %>%
xmlToDataFrame(xml)
html <- htmlParse(file = "books.html")
html <- read_html(html)
library(dbplyr)
library(dplyr)
library(htmltools)
library(htmlwidgets)
detach("package:maps", unload = TRUE)
library(maps)
library(RColorBrewer)
library(rjson)
library(rmarkdown)
library(RMySQL)
library(rvest)
library(stringr)
library(tidyverse)
library(tidyr)
library(XML)
html <- htmlParse(file = "books.html")
html <- read_html(html)
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
html <- htmlParse(file = "books.html")
html <- read_html(html)
html
setwd("~/CUNY/DATA606")
0.02*400
p_hats1 <- rep(0, 5000)
p_hats2 <- rep(0, 5000)
p_hats3 <- rep(0, 5000)
p_hats4 <- rep(0, 5000)
p <- 0.1
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats1[i] <- sum(samp == "atheist")/n
}
p <- 0.1
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats2[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 1040
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats3[i] <- sum(samp == "atheist")/n
}
p <- 0.02
n <- 400
for(i in 1:5000){
samp <- sample(c("atheist", "non_atheist"), n, replace = TRUE, prob = c(p, 1-p))
p_hats4[i] <- sum(samp == "atheist")/n
}
par(mfrow = c(2, 2))
hist(p_hats1, main = "p = 0.1, n = 1040", xlim = c(0, 0.18))
hist(p_hats2, main = "p = 0.1, n = 400", xlim = c(0, 0.18))
hist(p_hats3, main = "p = 0.02, n = 1040", xlim = c(0, 0.18))
hist(p_hats4, main = "p = 0.02, n = 400", xlim = c(0, 0.18))
par(mfrow = c(1,1))
View(atheism)
spain5 <- subset(atheism, nationality == "Spain" & year == "2005")
spain12 <- subset(atheism, nationality == "Spain" & year == "2012")
inference(spain5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
us5 <- subset(atheism, nationality == "United States" & year == "2005")
us12 <- subset(atheism, nationality == "United States" & year == "2012")
inference(us5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(us12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(us12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(us5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(us12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain12$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain5$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
((0.01/1.96)^2)
((0.5*0.5)/(0.01/1.96)^2)
spain5 <- subset(atheism, nationality == "Spain"S)
spain <- subset(atheism, nationality == "Spain"S)
spain <- subset(atheism, nationality == "Spain")
inference(spain$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
inference(spain$response, est = "proportion", type = "ci", method = "theoretical", success = "atheist")
library(XML)
html <- htmlParse(file = "books.html")
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
setwd("~/CUNY/DATA607/Assignments/XML and JSON")
library(XML)
html <- htmlParse(file = "books.html")
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
class(html)
html <- readHTMLTable(html)
View(html)
html <- htmlParse(file = "books.html")
html <- readHTMLList(html)
View(html)
html <- htmlParse(file = "books.html")
read_html(html)
1.96*((0.48*(1-0.48))/1259)^(1/2)
0.48+0.0276
0.48-0.0276
(0.48*(1-0.48))/((0.02/1.96)^2)
(((0.08*0.92)/11545)+((0.088*0.912)/4691))^(1/2)
0.08-0.088
1.96*0.00485
0.009506+0.008
0.009506-0.008
-0.008+0.009506
-0.008-0.009506
setwd("~/R")
h <- read.csv("hasz.csv", header = FLASE)
h <- read.csv("hasz.csv", header = FALSE)
View(h)
plot(h$V1, h$V2)
install.packages("plotly")
library(plotly)
kd <- with(MASS::geyser, MASS::kde2d(duration, waiting, n = 50))
fig <- plot_ly(x = h$V1, y = h$V2, z = h$V3) %>% add_surface()
fig
fig <- plot_ly(z = ~h)
fig <- fig %>% add_surface()
fig
class(h$V3)
fig <- plot_ly(z = ~volcano)
fig <- fig %>% add_surface()
fig
fig <- plot_ly(z = ~volcano)
fig <- fig %>% add_surface()
fig
fig <- plot_ly(z = ~volcano)
fig <- fig %>% add_surface()
fig
plot(x = h$V1, y = h$V2, z = h$V3)
h(names) <- c("x","y","Energy")
warnings()
h(names) <- c("x","y","Energy")
names(h) <- c("x","y","Energy")
ggplot(h, aes(x,y)) + geom_point()
h$Energy
install.packages(c("rgl", "car"))
library("car")
scatter3d(H$x, h$y, h$z)
scatter3d(h$x, h$y, h$z)
scatter3d(x = h$x, y = h$y, z = h$Energy,
point.col = "blue", surface=TRUE)
scatter3d(x = h$x, y = h$y, z = h$Energy, point.col = "blue", surface=FALSE)
library(rsm)
install.packages("rsm")
library(rsm)
fit <- lm(h$Energy ~ poly(h$x, h$y, degree = 2), data = h)
SurfMod <- contour(fit, h$y ~ h$x)
View(fit)
image(fit, h$y ~ h$x)
x <- h$x
y <- h$y
z <- h$Energy
fit <- lm(z ~ poly(x, y, degree = 2), data = h)
SurfMod <- contour(fit, y ~ x)
Xvals <- SurfMod$`x ~ y`[1]
Yvals <- SurfMod$`x ~ y`[2]
Zvals <- SurfMod$`x ~ y`[3]
SurfMatrix <- Zvals$z
colnames(SurfMatrix) <- Yvals$y
rownames(SurfMatrix) <- Xvals$x
install.packages("reshape2")
library(reshape2)
SurfDF <- melt(SurfMatrix)
gg <- ggplot(data = SurfDF) +
geom_tile(data = SurfDF, aes(Var1, Var2,z = value, fill = value)) +
stat_contour(data = SurfDF, aes(Var1, Var2, z = value, color = ..level..)) +
scale_colour_gradient(low = "green", high = "red") +
geom_point(data = DATA, aes(h, y, z = z, color = z)) +
geom_text(data = DATA, aes(h, y,label=z),hjust=0, vjust=0) +
scale_fill_continuous(name="z") +
xlab("x") +
ylab("y")
gg <- ggplot(data = SurfDF) +
geom_tile(data = SurfDF, aes(Var1, Var2,z = value, fill = value)) +
stat_contour(data = SurfDF, aes(Var1, Var2, z = value, color = ..level..)) +
scale_colour_gradient(low = "green", high = "red") +
geom_point(data = h, aes(x, y, z = , color = z)) +
geom_text(data = h, aes(x, y,label=z),hjust=0, vjust=0) +
scale_fill_continuous(name="z") +
xlab("x") +
ylab("y")
gg <- ggplot(data = SurfDF) +
geom_tile(data = SurfDF, aes(Var1, Var2,z = value, fill = value)) +
stat_contour(data = SurfDF, aes(Var1, Var2, z = value, color = ..level..)) +
scale_colour_gradient(low = "green", high = "red") +
geom_point(data = h, aes(x, y, z = Energy, color = Energy)) +
geom_text(data = h, aes(x, y,label=Energy),hjust=0, vjust=0) +
scale_fill_continuous(name="Energy") +
xlab("x") +
ylab("y")
image(fit, y ~ x)
contour(fit, y ~ x)
persp(fit, y ~ x, zlab = "z")
library(jsonlite)
library(XML)
html <- htmlParse(file = "books.html")
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
setwd("~/CUNY/DATA607/Assignments/XML and JSON")
html <- htmlParse(file = "books.html")
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
json <- fromJSON("books.json")
View(json)
json
json <- json$books
View(json)
View(xml)
library(rvest)
my_df <- as.data.frame(read_html(html) %>% html_table(fill=TRUE))
my_df <- as.data.frame(read_html("books.html") %>% html_table(fill=TRUE))
View(my_df)
library(XML)
library(jsonlite)
library(rvest)
html <- as.data.frame(read_html("books.html") %>% html_table(fill = TRUE))
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
json <- fromJSON("books.json")
json <- json$books
View(html)
html <- as.data.frame(read_html("books.html") %>% html_table(fill = FALSE))
View(my_df)
View(html)
library(XML)
library(jsonlite)
library(rvest)
html <- as.data.frame(read_html("books.html") %>% html_table())
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
json <- fromJSON("books.json")
json <- json$books
library(XML)
library(jsonlite)
library(rvest)
html <- as.data.frame(read_html("books.html"))
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
json <- fromJSON("books.json")
json <- json$books
View(html)
View(json)
View(xml)
detach("package:rvest", unload = TRUE)
library(XML)
library(jsonlite)
html <- as.data.frame(read_html("books.html") %>% html_table())
xml <- xmlParse(file = "books.xml")
xml <- xmlRoot(xml)
xml <- xmlToDataFrame(xml)
json <- fromJSON("books.json")
json <- json$books
View(html)
View(html)
View(xml)
View(json)
setwd("~/CUNY/DATA607/Projects/Project 3")
library(rvest)
library(tidyverse)
links <- read.csv("data_science_links.csv", header = FALSE)
names(links) <- c("Link")
links$Link <- as.character(links$Link)
goal <- c()
for(i in 1:length(links$Link)){
h_text <- read_html(links[i,]) %>%
html_nodes("li") %>%
html_text()
for(j in 1:length(h_text)){
goal <- str_c(goal, h_text[j], sep = " ")
}
}
goal <- str_extract_all(goal, boundary("word"))
big_list <- c()
for(i in 1:length(goal)){
for(j in 1:length(goal[[i]])){
big_list <- c(big_list, tolower(goal[[i]][j]))
}
}
sums <- c()
for(i in 1:length(big_list)){
sums <- c(sums, sum(big_list == big_list[i]))
}
small_data <- data.frame(big_list, sums)
small_data <- small_data[!duplicated(small_data$big_list), ] %>%
filter(sums <= 150) %>%
filter(sums >= 50)
library(rvest)
library(tidyverse)
links <- read.csv("data_science_links.csv", header = FALSE)
names(links) <- c("Link")
links$Link <- as.character(links$Link)
goal <- c()
for(i in 1:length(links$Link)){
h_text <- read_html(links[i,]) %>%
html_nodes("li") %>%
html_text()
for(j in 1:length(h_text)){
goal <- str_c(goal, h_text[j], sep = " ")
}
}
goal <- str_extract_all(goal, boundary("word"))
big_list <- c()
for(i in 1:length(goal)){
for(j in 1:length(goal[[i]])){
big_list <- c(big_list, tolower(goal[[i]][j]))
}
}
sums <- c()
for(i in 1:length(big_list)){
sums <- c(sums, sum(big_list == big_list[i]))
}
small_data <- data.frame(big_list, sums)
small_data <- small_data[!duplicated(small_data$big_list), ] %>%
filter(sums <= 150) %>%
filter(sums >= 50)
library(rvest)
library(tidyverse)
links <- read.csv("data_science_links.csv", header = FALSE)
library(rvest)
library(tidyverse)
links <- read.csv("data_science_links.csv", header = FALSE)
names(links) <- c("Link")
links$Link <- as.character(links$Link)
goal <- c()
for(i in 1:length(links$Link)){
h_text <- read_html(links[i,]) %>%
html_nodes("li") %>%
html_text()
for(j in 1:length(h_text)){
goal <- str_c(goal, h_text[j], sep = " ")
}
}
goal <- str_extract_all(goal, boundary("word"))
big_list <- c()
for(i in 1:length(goal)){
for(j in 1:length(goal[[i]])){
big_list <- c(big_list, tolower(goal[[i]][j]))
}
}
sums <- c()
for(i in 1:length(big_list)){
sums <- c(sums, sum(big_list == big_list[i]))
}
small_data <- data.frame(big_list, sums)
small_data <- small_data[!duplicated(small_data$big_list), ] %>%
filter(sums <= 150) %>%
filter(sums >= 50)
View(small_data)
